{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluating Model Performance\n",
    "We'll investigate several different algorithms and determine which is best at modeling the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation - Creating a Training and Predicting Pipeline\n",
    "\n",
    "To properly evaluate the performance of various models, we need to create a training and predicting pipeline that allows for quick and effective model training using various sizes of training data and perform predictions on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(results, mae):\n",
    "\n",
    "def evaluate(results):\n",
    "    \"\"\"\n",
    "    Visualization code to display results of various learners.\n",
    "    \n",
    "    inputs:\n",
    "      - results: a list of supervised learners\n",
    "      - stats: a list of dictionaries of the statistic results from 'train_predict()'\n",
    "      - mae: Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price\n",
    "    \"\"\"\n",
    "  \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(2, 2, figsize = (7,9))\n",
    "\n",
    "    # Constants\n",
    "    bar_width = 0.3\n",
    "    colors = ['#A00000','#00A0A0','#00A000']\n",
    "    \n",
    "    # Super loop to plot four panels of data\n",
    "    for k, learner in enumerate(results.keys()):\n",
    "        for j, metric in enumerate(['train_time', 'mae_train', 'pred_time', 'mae_test']):\n",
    "            for i in np.arange(3):\n",
    "                \n",
    "                # Creative plot code\n",
    "                ax[j//2, j%2].bar(i+k*bar_width, results[learner][i][metric], width = bar_width, color = colors[k])\n",
    "                ax[j//2, j%2].set_xticks([0.45, 1.45, 2.45])\n",
    "                ax[j//2, j%2].set_xticklabels([\"1%\", \"10%\", \"100%\"])\n",
    "                ax[j//2, j%2].set_xlabel(\"Training Set Size\")\n",
    "                ax[j//2, j%2].set_xlim((-0.1, 3.0))\n",
    "    \n",
    "    # Add unique y-labels\n",
    "    ax[0, 0].set_ylabel(\"Time (in seconds)\")\n",
    "    ax[0, 1].set_ylabel(\"MAE Score\")\n",
    "    ax[1, 0].set_ylabel(\"Time (in seconds)\")\n",
    "    ax[1, 1].set_ylabel(\"MAE Score\")\n",
    "    \n",
    "    # Add titles\n",
    "    ax[0, 0].set_title(\"Model Training\")\n",
    "    ax[0, 1].set_title(\"MAE Score on Training Subset\")\n",
    "    ax[1, 0].set_title(\"Model Predicting\")\n",
    "    ax[1, 1].set_title(\"MAE Score on Testing Set\")\n",
    "    \n",
    "#     # Set y-limits for score panels\n",
    "#     ax[0, 1].set_ylim((0, 1))\n",
    "#     ax[1, 1].set_ylim((0, 1))\n",
    "\n",
    "    # Create patches for the legend\n",
    "    patches = []\n",
    "    for i, learner in enumerate(results.keys()):\n",
    "        patches.append(plt.mpatches.Patch(color = colors[i], label = learner))\n",
    "    plt.legend(handles = patches, bbox_to_anchor = (-.80, 2.53), \\\n",
    "               loc = 'upper center', borderaxespad = 0., ncol = 3, fontsize = 'x-large')\n",
    "    \n",
    "    # Aesthetics\n",
    "    plt.suptitle(\"Performance Metrics for Three Supervised Learning Models\", fontsize = 16, y = 1.10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Fit the learner to the training data using slicing with 'sample_size' using .fit(training_features[:], training_labels[:])\n",
    "    start = time() # Get start time\n",
    "    learner = learner.fit(X_train[:sample_size], y_train[:sample_size])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "        \n",
    "    # Get the predictions on the test set(X_test),\n",
    "    #   then get predictions on the first 300 training samples(X_train) using .predict()\n",
    "    start = time() # Get start time\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train[:200])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # Calculate the total prediction time\n",
    "    results['pred_time'] = end - start\n",
    "    \n",
    "    # Compute MAE on the first 200 training samples which is y_train[:200]\n",
    "    results['mae_train'] = mean_squared_error(y_train[:200], predictions_train[:200], squared=False)\n",
    "    \n",
    "    # Compute MAE on test set\n",
    "    results['mae_test'] = mean_squared_error(y_test, predictions_test, squared=False)\n",
    "       \n",
    "    # Success\n",
    "    print(f'{learner.__class__.__name__} trained on {sample_size} samples.')\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: Initial Model Evaluation\n",
    "\n",
    "**Note:** Depending on chosen algorithms, the following implementation may take some time to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import the three supervised learning models from sklearn\n",
    "\n",
    "from sklearn.linear_model import TweedieRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# TODO: Initialize the three models\n",
    "rgsr_A = TweedieRegressor(power=2, link='log')\n",
    "rgsr_B = RandomForestRegressor(random_state=5)\n",
    "rgsr_C = AdaBoostRegressor(random_state=5)\n",
    "\n",
    "# Calculate the number of samples for 1%, 10%, and 100% of the training data\n",
    "# samples_100 is the entire training set i.e. len(y_train)\n",
    "# samples_10 is 10% of samples_100\n",
    "# samples_1 is 1% of samples_100\n",
    "samples_100 = len(y_train)\n",
    "samples_10 = np.int_((samples_100 * 0.1))\n",
    "samples_1 = np.int_((samples_100 * 0.01))\n",
    "\n",
    "# Collect results on the learners\n",
    "results = {}\n",
    "for rgsr in [rgsr_A, rgsr_B, rgsr_C]:\n",
    "    rgsr_name = rgsr.__class__.__name__\n",
    "    results[rgsr_name] = {}\n",
    "    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n",
    "        results[rgsr_name][i] = \\\n",
    "        train_predict(rgsr, samples, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Run metrics visualization for the three supervised learning models chosen\n",
    "evaluate(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HousingEnv",
   "language": "python",
   "name": "housingenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
